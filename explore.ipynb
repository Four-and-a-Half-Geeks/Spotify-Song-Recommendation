{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing LLM and Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imports\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Functions\n",
    "def get_song_name(response : str) -> str:\n",
    "    # Process the response to extract only the song name\n",
    "    # Assuming the format is like: '\"Out of Love\" is a song by Avicii.'\n",
    "    start_quote_index = response.find('\"')  # Find the index of the first quote\n",
    "    end_quote_index = response.find('\"', start_quote_index + 1)  # Find the index of the closing quote\n",
    "\n",
    "    if start_quote_index != -1 and end_quote_index != -1:\n",
    "        # Extract the song name using slicing\n",
    "        song_name = response[start_quote_index + 1:end_quote_index]\n",
    "        return song_name\n",
    "    else:\n",
    "        return \"Song name not found.\"\n",
    "    \n",
    "def get_track_from_spotify(spotify_client_id, spotify_client_secret, song_name : str) -> str:\n",
    "    auth_manager = SpotifyClientCredentials(client_id=spotify_client_id, client_secret=spotify_client_secret)\n",
    "    sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "    # Search for the song\n",
    "    results = sp.search(q=song_name, type='track', limit=1)\n",
    "\n",
    "    # Extract track information\n",
    "    if results['tracks']['items']:\n",
    "        track = results['tracks']['items'][0]\n",
    "        return(f\"Found track: {track['name']} by {track['artists'][0]['name']}\")\n",
    "    else:\n",
    "        return(\"Song not found.\")\n",
    "    \n",
    "def prompt_llm(prompt : str, prompt_template : PromptTemplate = PromptTemplate()) -> str:\n",
    "    llm = HuggingFaceHub(\n",
    "    repo_id=\"ibm-granite/granite-3.0-3b-a800m-instruct\",  # replace with the model name you want\n",
    "    huggingfacehub_api_token=os.getenv('HUGGING_FACE_TOKEN')\n",
    "    )\n",
    "    if prompt_template:\n",
    "        llm_chain = LLMChain(llm= llm, prompt= prompt_template)\n",
    "        response = llm_chain.run(prompt)\n",
    "    else:\n",
    "        response = llm(prompt)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace these with your actual Spotify API credentials\n",
    "client_id = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "client_secret = os.getenv('SPOTIFY_CLIENT_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Langchain model\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"ibm-granite/granite-3.0-3b-a800m-instruct\",  # replace with the model name you want\n",
    "    huggingfacehub_api_token=os.getenv('HUGGING_FACE_TOKEN')\n",
    ")\n",
    "\n",
    "# Generate text with the LangChain LLM\n",
    "response = llm(\"Recommend me a song from Metallica. But include in your response only the name of the song, and only one song.\")\n",
    "#print(response)\n",
    "\n",
    "song_name = get_song_name(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found track: Enter Sandman (Remastered) by Metallica\n"
     ]
    }
   ],
   "source": [
    "print(get_track_from_spotify(client_id, client_secret, song_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using promt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_description = 'Instrumental music with a piano in the background'\n",
    "\n",
    "#Templates\n",
    "song_template = PromptTemplate(\n",
    "    input_variables=['description'],\n",
    "    template='Recommend me a song that matches this description: {song_description}.\\\n",
    "        Include in your response only the name of the song, and only one song.'\n",
    ")\n",
    "\n",
    "    \n",
    "song_name = get_song_name(prompt_llm(song_template, song_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found track: Clair de lune by Claude Debussy\n"
     ]
    }
   ],
   "source": [
    "print(get_track_from_spotify(client_id, client_secret, song_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify_llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
